{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing library\n",
    "\n",
    "import numpy as np         # linear algebra\n",
    "import pandas as pd        # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring Warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Dataset\n",
    "\n",
    "import os\n",
    "os.chdir(\"C:/Users/swethabalaji/Downloads\")\n",
    "df=pd.read_csv(\"OnlineNewsPopularity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 61)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing space character in the feature names\n",
    "\n",
    "df.columns=df.columns.str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping  url & timedelta\n",
    "\n",
    "df1=df.drop([\"url\",\"timedelta\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 59)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping catogorical values from df1.\n",
    "# Now df2_num  dataframe contains numerical feaures.\n",
    "\n",
    "df2_num=df1.drop([\"weekday_is_monday\",\"weekday_is_tuesday\",\"weekday_is_wednesday\",\"weekday_is_thursday\",\n",
    "                  \"weekday_is_friday\",\"weekday_is_saturday\",\"weekday_is_sunday\",\"is_weekend\",                  \n",
    "                  \"data_channel_is_lifestyle\",\"data_channel_is_entertainment\",\"data_channel_is_bus\",\n",
    "                  \"data_channel_is_socmed\",\"data_channel_is_tech\",\"data_channel_is_world\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 45)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2_cat dataframe contains catagoricl features.\n",
    "\n",
    "df2_cat=df1[[\"weekday_is_monday\",\"weekday_is_tuesday\",\"weekday_is_wednesday\",\"weekday_is_thursday\",\n",
    "             \"weekday_is_friday\",\"weekday_is_saturday\",\"weekday_is_sunday\",\"is_weekend\",            \n",
    "             \"data_channel_is_lifestyle\",\"data_channel_is_entertainment\",\"data_channel_is_bus\",\n",
    "                  \"data_channel_is_socmed\",\"data_channel_is_tech\",\"data_channel_is_world\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 14)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping highly correlated features and target feature\n",
    "\n",
    "df2_num_new=df2_num.drop([\"n_non_stop_unique_tokens\",\"n_non_stop_words\",\"kw_avg_min\",\"shares\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 41)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_num_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new copy of df2_num_new\n",
    "\n",
    "df3=df2_num_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying power transformation. method = BOX-COX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_tokens_content', 'n_unique_tokens', 'num_hrefs', 'num_self_hrefs',\n",
       "       'num_imgs', 'num_videos', 'average_token_length', 'kw_min_min',\n",
       "       'kw_max_min', 'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg',\n",
       "       'kw_max_avg', 'kw_avg_avg', 'self_reference_min_shares',\n",
       "       'self_reference_max_shares', 'self_reference_avg_sharess', 'LDA_00',\n",
       "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
       "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
       "       'global_rate_negative_words', 'rate_positive_words',\n",
       "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
       "       'max_positive_polarity', 'avg_negative_polarity',\n",
       "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
       "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
       "       'abs_title_sentiment_polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding negative values.\n",
    "\n",
    "negcols=df3.columns[(df3<=0).any()]\n",
    "negcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens_content_new\n",
      "n_unique_tokens_new\n",
      "num_hrefs_new\n",
      "num_self_hrefs_new\n",
      "num_imgs_new\n",
      "num_videos_new\n",
      "average_token_length_new\n",
      "kw_min_min_new\n",
      "kw_max_min_new\n",
      "kw_min_max_new\n",
      "kw_max_max_new\n",
      "kw_avg_max_new\n",
      "kw_min_avg_new\n",
      "kw_max_avg_new\n",
      "kw_avg_avg_new\n",
      "self_reference_min_shares_new\n",
      "self_reference_max_shares_new\n",
      "self_reference_avg_sharess_new\n",
      "LDA_00_new\n",
      "LDA_01_new\n",
      "LDA_02_new\n",
      "LDA_03_new\n",
      "LDA_04_new\n",
      "global_subjectivity_new\n",
      "global_sentiment_polarity_new\n",
      "global_rate_positive_words_new\n",
      "global_rate_negative_words_new\n",
      "rate_positive_words_new\n",
      "rate_negative_words_new\n",
      "avg_positive_polarity_new\n",
      "min_positive_polarity_new\n",
      "max_positive_polarity_new\n",
      "avg_negative_polarity_new\n",
      "min_negative_polarity_new\n",
      "max_negative_polarity_new\n",
      "title_subjectivity_new\n",
      "title_sentiment_polarity_new\n",
      "abs_title_subjectivity_new\n",
      "abs_title_sentiment_polarity_new\n"
     ]
    }
   ],
   "source": [
    "#converting negative values to positive values for applying Box-Cox method and creating new feature.\n",
    "\n",
    "for i in negcols:\n",
    "    m=df3[i].min()\n",
    "    name=i +'_new'\n",
    "    print(name)\n",
    "    df3[name]=((df3[i]+1)-m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping old negative column\n",
    "\n",
    "for i in negcols:\n",
    "    df3.drop(i,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking negative columns\n",
    "\n",
    "negcols=df3.columns[(df3<=0).any()]\n",
    "negcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Box-cox Method\n",
    "\n",
    "from sklearn import preprocessing\n",
    "pt=preprocessing.PowerTransformer(method='box-cox',standardize=False)\n",
    "BC_data=pt.fit_transform(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_data=(pd.DataFrame(BC_data,columns=df3.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outlier once again after applying Box-Cox method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    39644.000000\n",
       "mean        13.350379\n",
       "std          3.982982\n",
       "min          0.000000\n",
       "25%         11.828717\n",
       "50%         13.193647\n",
       "75%         14.753095\n",
       "max         55.991639\n",
       "Name: kw_max_min_new, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_data['kw_max_min_new'].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating outlier :  \n",
    "\n",
    "for col in bc_data.columns:\n",
    "    percentiles = bc_data[col].quantile([0.01,0.99]).values\n",
    "    bc_data[col][bc_data[col] <= percentiles[0]] = percentiles[0]\n",
    "    bc_data[col][bc_data[col] >= percentiles[1]] = percentiles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining numeric features and catogorical features.\n",
    "\n",
    "df3_con=pd.concat([bc_data,df2_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 55)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_con.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y=df1['shares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_con['popularity'] = pd.qcut(df1['shares'], 3, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the label by threshold 1400\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "popular_label = pd.Series(label_encoder.fit_transform(df1['shares']>=1400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df3_con['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df3_con.drop('popularity',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14732\n",
       "2    12955\n",
       "1    11957\n",
       "Name: popularity, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# with all features as input\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression To the training set  and predict with test data\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3563  939    0]\n",
      " [2668  886    0]\n",
      " [2814 1024    0]]\n",
      "Accuracy : 0.3740541449470321\n"
     ]
    }
   ],
   "source": [
    "# making confusion matrix between \n",
    "#  test set of Y and predicted value. \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print('Accuracy : ' + str(accuracy_score(y_test, y_pred)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 6.01065046e-27, 2.69468605e-29, 1.53811980e-29,\n",
       "       4.26581319e-31, 1.31153269e-31, 1.03918255e-31, 9.41663565e-32,\n",
       "       5.87478906e-32, 3.82411763e-32, 1.36531766e-32, 1.04647540e-32,\n",
       "       9.75323070e-33, 9.75323070e-33, 9.75323070e-33, 9.75323070e-33,\n",
       "       9.75323070e-33, 9.75323070e-33, 9.75323070e-33, 9.75323070e-33,\n",
       "       9.75323070e-33, 9.75323070e-33, 9.75323070e-33, 9.75323070e-33,\n",
       "       9.75323070e-33, 9.75323070e-33, 9.75323070e-33, 9.75323070e-33,\n",
       "       9.75323070e-33, 9.75323070e-33, 9.75323070e-33, 9.75323070e-33,\n",
       "       9.75323070e-33, 9.75323070e-33, 9.75323070e-33, 9.75323070e-33,\n",
       "       9.75323070e-33, 9.75323070e-33, 9.75323070e-33, 9.75323070e-33,\n",
       "       9.75323070e-33, 9.75323070e-33, 9.75323070e-33, 9.75323070e-33,\n",
       "       9.75323070e-33, 9.75323070e-33, 9.75323070e-33, 9.75323070e-33,\n",
       "       9.75323070e-33, 9.75323070e-33, 9.75323070e-33, 9.75323070e-33,\n",
       "       9.75323070e-33, 9.34106147e-33, 9.08198488e-35])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SCREE PLOT\n",
    "#Explained variance\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA using 2 features\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.36767567567567566\n",
      "Test Score:  0.3740541449470321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logr = LogisticRegression()\n",
    "\n",
    "logr.fit(X_train,y_train)\n",
    "ypred=logr.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,logr.score(X_train, y_train)) #trainscore\n",
    "\n",
    "lr_score=metrics.accuracy_score(y_test, ypred)\n",
    "print(\"Test Score: \", lr_score) #testscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore.append(['log',lr_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.79      0.53      4502\n",
      "           1       0.31      0.25      0.28      3554\n",
      "           2       0.00      0.00      0.00      3838\n",
      "\n",
      "   micro avg       0.37      0.37      0.37     11894\n",
      "   macro avg       0.23      0.35      0.27     11894\n",
      "weighted avg       0.24      0.37      0.28     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.36418018018018017\n",
      "Test Score:  0.31133344543467295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "ypred1=knn.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,knn.score(X_train, y_train)) #trainscore\n",
    "\n",
    "knn_score=metrics.accuracy_score(y_test, ypred1)\n",
    "print(\"Test Score: \", knn_score) #testscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore.append(['Knn',knn_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.07      0.11      4502\n",
      "           1       0.50      0.00      0.00      3554\n",
      "           2       0.32      0.88      0.47      3838\n",
      "\n",
      "   micro avg       0.31      0.31      0.31     11894\n",
      "   macro avg       0.36      0.32      0.19     11894\n",
      "weighted avg       0.35      0.31      0.19     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.3796756756756757\n",
      "Test Score:  0.38590886161089627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc=DecisionTreeClassifier()\n",
    "dtc.fit(X_train,y_train)\n",
    "\n",
    "ypred2=dtc.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,dtc.score(X_train, y_train)) #trainscore\n",
    "\n",
    "dtc_score=metrics.accuracy_score(y_test, ypred2)\n",
    "print(\"Test Score: \", dtc_score) #testscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore.append(['DT',dtc_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.94      0.55      4502\n",
      "           1       0.35      0.08      0.13      3554\n",
      "           2       0.32      0.02      0.04      3838\n",
      "\n",
      "   micro avg       0.39      0.39      0.39     11894\n",
      "   macro avg       0.35      0.35      0.24     11894\n",
      "weighted avg       0.35      0.39      0.26     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.37535135135135134\n",
      "Test Score:  0.38952412981335127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gb=GaussianNB()\n",
    "gb.fit(X_train,y_train)\n",
    "\n",
    "ypred3=gb.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,gb.score(X_train, y_train)) #trainscore\n",
    "\n",
    "gb_score=metrics.accuracy_score(y_test, ypred3)\n",
    "print(\"Test Score: \", gb_score) #testscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore.append(['GB',gb_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.89      0.55      4502\n",
      "           1       0.32      0.09      0.14      3554\n",
      "           2       0.44      0.08      0.13      3838\n",
      "\n",
      "   micro avg       0.39      0.39      0.39     11894\n",
      "   macro avg       0.38      0.35      0.27     11894\n",
      "weighted avg       0.39      0.39      0.29     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.37963963963963965\n",
      "Test Score:  0.38590886161089627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "ypred4=rf.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,rf.score(X_train, y_train)) #trainscore\n",
    "\n",
    "rf_score=metrics.accuracy_score(y_test, ypred4)\n",
    "print(\"Test Score: \", rf_score) #testscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore.append(['rf',rf_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.95      0.55      4502\n",
      "           1       0.35      0.07      0.11      3554\n",
      "           2       0.32      0.02      0.04      3838\n",
      "\n",
      "   micro avg       0.39      0.39      0.39     11894\n",
      "   macro avg       0.35      0.35      0.24     11894\n",
      "weighted avg       0.36      0.39      0.26     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DT', 0.38590886161089627], ['rf', 0.38590886161089627]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Knn</td>\n",
       "      <td>0.297125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log</td>\n",
       "      <td>0.374054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.385909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GB</td>\n",
       "      <td>0.389524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.390701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name     Score\n",
       "1  Knn  0.297125\n",
       "0  log  0.374054\n",
       "2   DT  0.385909\n",
       "3   GB  0.389524\n",
       "4   rf  0.390701"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame(modelscore, columns =['Name', 'Score']) \n",
    "scores.sort_values(by=['Score'], inplace=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "logrboost=ABC(base_estimator=logr,n_estimators=50)\n",
    "#knnboost=ABC(base_estimator=knn,n_estimators=50)\n",
    "dtboost=ABC(base_estimator=dtc,n_estimators=50)\n",
    "gtboost=ABC(base_estimator=gb,n_estimators=50)\n",
    "rfboost=ABC(base_estimator=rf,n_estimators=50)\n",
    "modelscore_PCA=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for model, name in zip([logrboost,dtboost,gtboost,rfboost],\n",
    "                       ['LogRBag','dtboost','gtboost','rfboost']):\n",
    "    #for train,test in kf.split(X,Y):\n",
    "       # Xtrain,Xtest=X.iloc[train,:],X.iloc[test,:]\n",
    "       # Ytrain,Ytest=Y[train],Y[test]\n",
    "    model.fit(X_train,y_train)\n",
    "    ypredict=model.predict(X_test)\n",
    "    modelscore_PCA.append([name,metrics.accuracy_score(y_test,ypredict)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scores = pd.DataFrame(modelscore_PCA, columns =['Name', 'Score']) \n",
    "scores.sort_values(by=['Score'], inplace=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import BaggingClassifier as BC\n",
    "logrboost=BC(base_estimator=logr,n_estimators=50)\n",
    "#knnboost=ABC(base_estimator=knn,n_estimators=50)\n",
    "dtboost=BC(base_estimator=dtc,n_estimators=50)\n",
    "gtboost=BC(base_estimator=gb,n_estimators=50)\n",
    "rfboost=BC(base_estimator=rf,n_estimators=50)\n",
    "modelscore_bagging_PCA=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for model, name in zip([logrboost,dtboost,gtboost,rfboost],\n",
    "                       ['LogRBag','dtbag','gtbag','rfbag']):\n",
    "    #for train,test in kf.split(X,Y):\n",
    "       # Xtrain,Xtest=X.iloc[train,:],X.iloc[test,:]\n",
    "       # Ytrain,Ytest=Y[train],Y[test]\n",
    "    model.fit(X_train,y_train)\n",
    "    ypredict=model.predict(X_test)\n",
    "    modelscore_bagging_PCA.append([name,metrics.accuracy_score(y_test,ypredict)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelscore_PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scores = pd.DataFrame(modelscore_bagging_PCA, columns =['Name', 'Score']) \n",
    "scores.sort_values(by=['Score'], inplace=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE Features:40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False False False False\n",
      " False  True  True False False  True  True  True False  True  True  True\n",
      "  True False  True  True False  True  True  True  True False False False\n",
      "  True False  True  True False  True  True]\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12 14  6  9\n",
      "  8  1  1 15 16  1  1  1 11  1  1  1  1  2  1  1 10  1  1  1  1  3  5  7\n",
      "  1 13  1  1  4  1  1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, 40)             # running RFE with 13 variables as output\n",
    "rfe = rfe.fit(X,y)\n",
    "print(rfe.support_)           # Printing the boolean results\n",
    "print(rfe.ranking_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['n_tokens_title', 'num_keywords', 'n_tokens_content_new',\n",
      "       'n_unique_tokens_new', 'num_hrefs_new', 'num_self_hrefs_new',\n",
      "       'num_imgs_new', 'num_videos_new', 'average_token_length_new',\n",
      "       'kw_min_min_new', 'kw_max_min_new', 'kw_min_max_new', 'kw_max_max_new',\n",
      "       'kw_avg_max_new', 'kw_min_avg_new', 'kw_max_avg_new', 'kw_avg_avg_new',\n",
      "       'self_reference_min_shares_new', 'self_reference_max_shares_new',\n",
      "       'self_reference_avg_sharess_new', 'global_subjectivity_new',\n",
      "       'global_sentiment_polarity_new', 'rate_positive_words_new',\n",
      "       'rate_negative_words_new', 'avg_positive_polarity_new',\n",
      "       'max_positive_polarity_new', 'avg_negative_polarity_new',\n",
      "       'min_negative_polarity_new', 'max_negative_polarity_new',\n",
      "       'title_sentiment_polarity_new', 'abs_title_subjectivity_new',\n",
      "       'weekday_is_monday', 'weekday_is_tuesday', 'weekday_is_wednesday',\n",
      "       'weekday_is_thursday', 'is_weekend', 'data_channel_is_entertainment',\n",
      "       'data_channel_is_bus', 'data_channel_is_tech', 'data_channel_is_world'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "model = LogisticRegression()\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, 40)             \n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X,y)  \n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y)              \n",
    "temp = pd.Series(rfe.support_,index = cols)\n",
    "selected_features_rfe = temp[temp==True].index\n",
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7=df3_con[['n_tokens_title', 'num_keywords', 'n_tokens_content_new',\n",
    "       'n_unique_tokens_new', 'num_hrefs_new', 'num_self_hrefs_new',\n",
    "       'num_imgs_new', 'num_videos_new', 'average_token_length_new',\n",
    "       'kw_min_min_new', 'kw_max_min_new', 'kw_min_max_new', 'kw_max_max_new',\n",
    "       'kw_avg_max_new', 'kw_min_avg_new', 'kw_max_avg_new', 'kw_avg_avg_new',\n",
    "       'self_reference_min_shares_new', 'self_reference_max_shares_new',\n",
    "       'self_reference_avg_sharess_new', 'LDA_04_new',\n",
    "       'global_subjectivity_new', 'global_sentiment_polarity_new',\n",
    "       'rate_positive_words_new', 'avg_positive_polarity_new',\n",
    "       'max_positive_polarity_new', 'avg_negative_polarity_new',\n",
    "       'min_negative_polarity_new', 'max_negative_polarity_new',\n",
    "       'title_subjectivity_new', 'title_sentiment_polarity_new',\n",
    "       'abs_title_subjectivity_new', 'weekday_is_saturday',\n",
    "       'weekday_is_sunday', 'is_weekend', 'data_channel_is_lifestyle',\n",
    "       'data_channel_is_entertainment', 'data_channel_is_socmed',\n",
    "       'data_channel_is_tech', 'data_channel_is_world']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 40)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore_rf=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.36864864864864866\n",
      "Test Score:  0.3785101731965697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logr_rf = LogisticRegression()\n",
    "\n",
    "logr_rf.fit(X_train,y_train)\n",
    "ypred=logr_rf.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,logr_rf.score(X_train, y_train)) #trainscore\n",
    "\n",
    "lrrfe_score=metrics.accuracy_score(y_test, ypred)\n",
    "print(\"Test Score: \", lrrfe_score) #testscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore_rf.append(['log_rfe',lrrfe_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.5733333333333334\n",
      "Test Score:  0.3669076845468303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_rf=KNeighborsClassifier()\n",
    "\n",
    "knn_rf.fit(X_train,y_train)\n",
    "ypred1=knn_rf.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,knn_rf.score(X_train, y_train)) #trainscore\n",
    "\n",
    "knnrfe_score=metrics.accuracy_score(y_test, ypred1)\n",
    "print(\"Test Score: \", knnrfe_score) #testscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.56      0.47      4502\n",
      "           1       0.31      0.28      0.29      3554\n",
      "           2       0.35      0.22      0.27      3838\n",
      "\n",
      "   micro avg       0.37      0.37      0.37     11894\n",
      "   macro avg       0.35      0.35      0.34     11894\n",
      "weighted avg       0.36      0.37      0.35     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore_rf.append(['knn_rfe',knnrfe_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  1.0\n",
      "Test Score:  0.40491003867496217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc_rf=DecisionTreeClassifier()\n",
    "dtc_rf.fit(X_train,y_train)\n",
    "\n",
    "ypred2=dtc_rf.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,dtc_rf.score(X_train, y_train)) #trainscore\n",
    "\n",
    "dtcrfe_score=metrics.accuracy_score(y_test, ypred2)\n",
    "print(\"Test Score: \", dtcrfe_score) #testscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore_rf.append(['dtc_rfe',dtcrfe_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.47      0.47      4502\n",
      "           1       0.31      0.31      0.31      3554\n",
      "           2       0.41      0.42      0.42      3838\n",
      "\n",
      "   micro avg       0.40      0.40      0.40     11894\n",
      "   macro avg       0.40      0.40      0.40     11894\n",
      "weighted avg       0.40      0.40      0.40     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.37535135135135134\n",
      "Test Score:  0.38952412981335127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gb_rf=GaussianNB()\n",
    "gb_rf.fit(X_train,y_train)\n",
    "\n",
    "ypred3=gb_rf.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,gb_rf.score(X_train, y_train)) #trainscore\n",
    "\n",
    "gbrfe_score=metrics.accuracy_score(y_test, ypred3)\n",
    "print(\"Test Score: \", gbrfe_score) #testscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore_rf.append(['gb_rfe',gbrfe_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.89      0.55      4502\n",
      "           1       0.32      0.09      0.14      3554\n",
      "           2       0.44      0.08      0.13      3838\n",
      "\n",
      "   micro avg       0.39      0.39      0.39     11894\n",
      "   macro avg       0.38      0.35      0.27     11894\n",
      "weighted avg       0.39      0.39      0.29     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.9864504504504504\n",
      "Test Score:  0.45375819741045903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_rfe=RandomForestClassifier()\n",
    "rf_rfe.fit(X_train,y_train)\n",
    "\n",
    "ypred4=rf_rfe.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,rf_rfe.score(X_train, y_train)) #trainscore\n",
    "\n",
    "rf_rfe_score=metrics.accuracy_score(y_test, ypred4)\n",
    "print(\"Test Score: \", rf_rfe_score) #testscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.60      0.55      4502\n",
      "           1       0.35      0.30      0.32      3554\n",
      "           2       0.46      0.43      0.44      3838\n",
      "\n",
      "   micro avg       0.45      0.45      0.45     11894\n",
      "   macro avg       0.44      0.44      0.44     11894\n",
      "weighted avg       0.45      0.45      0.45     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore_rf.append(['rf_rfe',rf_rfe_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn_rfe</td>\n",
       "      <td>0.366908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_rfe</td>\n",
       "      <td>0.378510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gb_rfe</td>\n",
       "      <td>0.389524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dtc_rfe</td>\n",
       "      <td>0.404910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf_rfe</td>\n",
       "      <td>0.453758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name     Score\n",
       "1  knn_rfe  0.366908\n",
       "0  log_rfe  0.378510\n",
       "3   gb_rfe  0.389524\n",
       "2  dtc_rfe  0.404910\n",
       "4   rf_rfe  0.453758"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame(modelscore_rf, columns =['Name', 'Score']) \n",
    "scores.sort_values(by=['Score'], inplace=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "logrboost=ABC(base_estimator=logr_rf,n_estimators=50)\n",
    "#knnboost=ABC(base_estimator=knn,n_estimators=50)\n",
    "dtboost=ABC(base_estimator=dtc_rf,n_estimators=50)\n",
    "gtboost=ABC(base_estimator=gb_rf,n_estimators=50)\n",
    "rfboost=ABC(base_estimator=rf_rfe,n_estimators=50)\n",
    "modelscore_RFE40=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, name in zip([logrboost,dtboost,gtboost,rfboost],\n",
    "                       ['LogRBag','dtboost','gtboost','rfboost']):\n",
    "    #for train,test in kf.split(X,Y):\n",
    "       # Xtrain,Xtest=X.iloc[train,:],X.iloc[test,:]\n",
    "       # Ytrain,Ytest=Y[train],Y[test]\n",
    "    model.fit(X_train,y_train)\n",
    "    ypredict=model.predict(X_test)\n",
    "    modelscore_RFE40.append([name,metrics.accuracy_score(y_test,ypredict)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogRBag</td>\n",
       "      <td>0.378510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gtboost</td>\n",
       "      <td>0.378678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dtboost</td>\n",
       "      <td>0.399109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfboost</td>\n",
       "      <td>0.468892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name     Score\n",
       "0  LogRBag  0.378510\n",
       "2  gtboost  0.378678\n",
       "1  dtboost  0.399109\n",
       "3  rfboost  0.468892"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame(modelscore_RFE40, columns =['Name', 'Score']) \n",
    "scores.sort_values(by=['Score'], inplace=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE Features:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['n_tokens_title', 'num_keywords', 'n_tokens_content_new',\n",
      "       'n_unique_tokens_new', 'num_hrefs_new', 'num_self_hrefs_new',\n",
      "       'num_imgs_new', 'num_videos_new', 'average_token_length_new',\n",
      "       'kw_min_min_new', 'kw_max_min_new', 'kw_min_max_new', 'kw_max_max_new',\n",
      "       'kw_avg_max_new', 'kw_min_avg_new', 'kw_max_avg_new', 'kw_avg_avg_new',\n",
      "       'self_reference_min_shares_new', 'self_reference_max_shares_new',\n",
      "       'self_reference_avg_sharess_new', 'LDA_02_new', 'LDA_03_new',\n",
      "       'LDA_04_new', 'global_subjectivity_new',\n",
      "       'global_sentiment_polarity_new', 'rate_positive_words_new',\n",
      "       'rate_negative_words_new', 'avg_positive_polarity_new',\n",
      "       'min_positive_polarity_new', 'max_positive_polarity_new',\n",
      "       'avg_negative_polarity_new', 'min_negative_polarity_new',\n",
      "       'max_negative_polarity_new', 'title_subjectivity_new',\n",
      "       'title_sentiment_polarity_new', 'abs_title_subjectivity_new',\n",
      "       'abs_title_sentiment_polarity_new', 'weekday_is_monday',\n",
      "       'weekday_is_tuesday', 'weekday_is_wednesday', 'weekday_is_thursday',\n",
      "       'weekday_is_friday', 'weekday_is_saturday', 'weekday_is_sunday',\n",
      "       'is_weekend', 'data_channel_is_entertainment', 'data_channel_is_bus',\n",
      "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
      "       'data_channel_is_world'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "model = LogisticRegression()\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, 50)             \n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X,y)  \n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y)              \n",
    "temp = pd.Series(rfe.support_,index = cols)\n",
    "selected_features_rfe = temp[temp==True].index\n",
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8=df3_con[['n_tokens_title', 'num_keywords', 'n_tokens_content_new',\n",
    "       'n_unique_tokens_new', 'num_hrefs_new', 'num_self_hrefs_new',\n",
    "       'num_imgs_new', 'num_videos_new', 'average_token_length_new',\n",
    "       'kw_min_min_new', 'kw_max_min_new', 'kw_min_max_new', 'kw_max_max_new',\n",
    "       'kw_avg_max_new', 'kw_min_avg_new', 'kw_max_avg_new', 'kw_avg_avg_new',\n",
    "       'self_reference_min_shares_new', 'self_reference_max_shares_new',\n",
    "       'self_reference_avg_sharess_new', 'LDA_04_new',\n",
    "       'global_subjectivity_new', 'global_sentiment_polarity_new',\n",
    "       'rate_positive_words_new', 'avg_positive_polarity_new',\n",
    "       'max_positive_polarity_new', 'avg_negative_polarity_new',\n",
    "       'min_negative_polarity_new', 'max_negative_polarity_new',\n",
    "       'title_subjectivity_new', 'title_sentiment_polarity_new',\n",
    "       'abs_title_subjectivity_new', 'weekday_is_saturday',\n",
    "       'weekday_is_sunday', 'is_weekend', 'data_channel_is_lifestyle',\n",
    "       'data_channel_is_entertainment', 'data_channel_is_socmed',\n",
    "       'data_channel_is_tech', 'data_channel_is_world']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 40)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df8\n",
    "modelscore_rf_50=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.36864864864864866\n",
      "Test Score:  0.3785101731965697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logr_rf = LogisticRegression()\n",
    "\n",
    "logr_rf.fit(X_train,y_train)\n",
    "ypred=logr_rf.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,logr_rf.score(X_train, y_train)) #trainscore\n",
    "\n",
    "lrrfe_score=metrics.accuracy_score(y_test, ypred)\n",
    "print(\"Test Score: \", lrrfe_score) #testscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE Features:35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['n_tokens_title', 'num_keywords', 'n_tokens_content_new',\n",
      "       'n_unique_tokens_new', 'num_hrefs_new', 'num_self_hrefs_new',\n",
      "       'num_imgs_new', 'num_videos_new', 'average_token_length_new',\n",
      "       'kw_min_min_new', 'kw_max_min_new', 'kw_min_max_new', 'kw_max_max_new',\n",
      "       'kw_avg_max_new', 'kw_min_avg_new', 'kw_max_avg_new', 'kw_avg_avg_new',\n",
      "       'self_reference_min_shares_new', 'self_reference_max_shares_new',\n",
      "       'self_reference_avg_sharess_new', 'global_subjectivity_new',\n",
      "       'global_sentiment_polarity_new', 'rate_positive_words_new',\n",
      "       'avg_positive_polarity_new', 'max_positive_polarity_new',\n",
      "       'avg_negative_polarity_new', 'min_negative_polarity_new',\n",
      "       'max_negative_polarity_new', 'title_subjectivity_new',\n",
      "       'title_sentiment_polarity_new', 'abs_title_subjectivity_new',\n",
      "       'is_weekend', 'data_channel_is_entertainment', 'data_channel_is_tech',\n",
      "       'data_channel_is_world'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "model = LogisticRegression()\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, 35)             \n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X,y)  \n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y)              \n",
    "temp = pd.Series(rfe.support_,index = cols)\n",
    "selected_features_rfe = temp[temp==True].index\n",
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9=df3_con[['n_tokens_title', 'num_keywords', 'n_tokens_content_new',\n",
    "       'num_hrefs_new', 'num_self_hrefs_new', 'num_imgs_new',\n",
    "       'average_token_length_new', 'kw_min_min_new', 'kw_max_min_new',\n",
    "       'kw_min_max_new', 'kw_max_max_new', 'kw_avg_max_new', 'kw_min_avg_new',\n",
    "       'kw_max_avg_new', 'kw_avg_avg_new', 'self_reference_min_shares_new',\n",
    "       'self_reference_max_shares_new', 'self_reference_avg_sharess_new',\n",
    "       'global_subjectivity_new', 'global_sentiment_polarity_new',\n",
    "       'rate_positive_words_new', 'avg_positive_polarity_new',\n",
    "       'max_positive_polarity_new', 'avg_negative_polarity_new',\n",
    "       'min_negative_polarity_new', 'max_negative_polarity_new',\n",
    "       'title_sentiment_polarity_new', 'abs_title_subjectivity_new',\n",
    "       'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend',\n",
    "       'data_channel_is_entertainment', 'data_channel_is_socmed',\n",
    "       'data_channel_is_tech', 'data_channel_is_world']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 35)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore_rf_35=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.36864864864864866\n",
      "Test Score:  0.3785101731965697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logr_rf = LogisticRegression()\n",
    "\n",
    "logr_rf.fit(X_train,y_train)\n",
    "ypred=logr_rf.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,logr_rf.score(X_train, y_train)) #trainscore\n",
    "\n",
    "lrrfe_score=metrics.accuracy_score(y_test, ypred)\n",
    "print(\"Test Score: \", lrrfe_score) #testscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore_rf.append(['rf_rfe',rf_rfe_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.55      4502\n",
      "           1       0.00      0.00      0.00      3554\n",
      "           2       0.00      0.00      0.00      3838\n",
      "\n",
      "   micro avg       0.38      0.38      0.38     11894\n",
      "   macro avg       0.13      0.33      0.18     11894\n",
      "weighted avg       0.14      0.38      0.21     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.5734774774774775\n",
      "Test Score:  0.3667395325374138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_rf=KNeighborsClassifier()\n",
    "\n",
    "knn_rf.fit(X_train,y_train)\n",
    "ypred1=knn_rf.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,knn_rf.score(X_train, y_train)) #trainscore\n",
    "\n",
    "knnrfe_2_score=metrics.accuracy_score(y_test, ypred1)\n",
    "print(\"Test Score: \", knnrfe_2_score) #testscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore_rf_35.append(['knnrfe_2',knnrfe_2_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.56      0.47      4502\n",
      "           1       0.31      0.28      0.29      3554\n",
      "           2       0.35      0.22      0.27      3838\n",
      "\n",
      "   micro avg       0.37      0.37      0.37     11894\n",
      "   macro avg       0.35      0.35      0.34     11894\n",
      "weighted avg       0.36      0.37      0.35     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  1.0\n",
      "Test Score:  0.41247687909870523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc_rf=DecisionTreeClassifier()\n",
    "dtc_rf.fit(X_train,y_train)\n",
    "\n",
    "ypred2=dtc_rf.predict(X_test)\n",
    "\n",
    "print(\"Train score: \" ,dtc_rf.score(X_train, y_train)) #trainscore\n",
    "\n",
    "dtcrfe_2_score=metrics.accuracy_score(y_test, ypred2)\n",
    "print(\"Test Score: \", dtcrfe_2_score) #testscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore_rf_35.append(['dtcrfe_2',dtcrfe_2_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.46      0.47      4502\n",
      "           1       0.34      0.35      0.34      3554\n",
      "           2       0.42      0.41      0.41      3838\n",
      "\n",
      "   micro avg       0.41      0.41      0.41     11894\n",
      "   macro avg       0.41      0.41      0.41     11894\n",
      "weighted avg       0.41      0.41      0.41     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.37535135135135134\n",
      "Test Score:  0.38952412981335127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gb_rf=GaussianNB()\n",
    "gb_rf.fit(X_train,y_train)\n",
    "\n",
    "ypred3=gb_rf.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,gb_rf.score(X_train, y_train)) #trainscore\n",
    "\n",
    "gbrfe_2_score=metrics.accuracy_score(y_test, ypred3)\n",
    "print(\"Test Score: \", gbrfe_2_score) #testscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore_rf_35.append(['gbrfe_2',gbrfe_2_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.89      0.55      4502\n",
      "           1       0.32      0.09      0.14      3554\n",
      "           2       0.44      0.08      0.13      3838\n",
      "\n",
      "   micro avg       0.39      0.39      0.39     11894\n",
      "   macro avg       0.38      0.35      0.27     11894\n",
      "weighted avg       0.39      0.39      0.29     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain score:  0.9846846846846847\n",
      "Test Score:  0.4440894568690096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_rfe=RandomForestClassifier()\n",
    "rf_rfe.fit(X_train,y_train)\n",
    "\n",
    "ypred4=rf_rfe.predict(X_test)\n",
    "\n",
    "print(\"Tain score: \" ,rf_rfe.score(X_train, y_train)) #trainscore\n",
    "\n",
    "rf_rfe2_score=metrics.accuracy_score(y_test, ypred4)\n",
    "print(\"Test Score: \", rf_rfe2_score) #testscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore_rf_35.append(['rf_rfe_2',rf_rfe2_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.55      4502\n",
      "           1       0.33      0.28      0.31      3554\n",
      "           2       0.45      0.41      0.43      3838\n",
      "\n",
      "   micro avg       0.44      0.44      0.44     11894\n",
      "   macro avg       0.43      0.43      0.43     11894\n",
      "weighted avg       0.43      0.44      0.44     11894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, ypred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knnrfe_2</td>\n",
       "      <td>0.366740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dtcrfe_2</td>\n",
       "      <td>0.412477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf_rfe_2</td>\n",
       "      <td>0.444089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name     Score\n",
       "0  knnrfe_2  0.366740\n",
       "1  dtcrfe_2  0.412477\n",
       "2  rf_rfe_2  0.444089"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame(modelscore_rf_35, columns =['Name', 'Score']) \n",
    "scores.sort_values(by=['Score'], inplace=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logrboost=ABC(base_estimator=logr_rf,n_estimators=50)\n",
    "#knnboost=ABC(base_estimator=knn,n_estimators=50)\n",
    "dtboost=ABC(base_estimator=dtc_rf,n_estimators=50)\n",
    "gtboost=ABC(base_estimator=gb_rf,n_estimators=50)\n",
    "rfboost=ABC(base_estimator=rf_rfe,n_estimators=50)\n",
    "modelscore_RFE35=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, name in zip([logrboost,dtboost,gtboost,rfboost],\n",
    "                       ['LogRBag','dtboost','gtboost','rfboost']):\n",
    "    #for train,test in kf.split(X,Y):\n",
    "       # Xtrain,Xtest=X.iloc[train,:],X.iloc[test,:]\n",
    "       # Ytrain,Ytest=Y[train],Y[test]\n",
    "    model.fit(X_train,y_train)\n",
    "    ypredict=model.predict(X_test)\n",
    "    modelscore_RFE35.append([name,metrics.accuracy_score(y_test,ypredict)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(modelscore_RFE35, columns =['Name', 'Score']) \n",
    "scores.sort_values(by=['Score'], inplace=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With all Features of df3_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df3_con.drop('popularity',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9859099099099099\n",
      "Test Score:  0.4511518412645031\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_rfe=RandomForestClassifier()\n",
    "rf_rfe.fit(X_train,y_train)\n",
    "\n",
    "ypred4=rf_rfe.predict(X_test)\n",
    "\n",
    "print(\"Train score: \" ,rf_rfe.score(X_train, y_train)) #trainscore\n",
    "\n",
    "rf_rfe_score=metrics.accuracy_score(y_test, ypred4)\n",
    "print(\"Test Score: \", rf_rfe_score) #testscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscore_RFE_allfeatures=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfboost=ABC(base_estimator=rf_rfe,n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, name in zip([rfboost],\n",
    "                       ['rfboost_allFeatures']):\n",
    "    #for train,test in kf.split(X,Y):\n",
    "       # Xtrain,Xtest=X.iloc[train,:],X.iloc[test,:]\n",
    "       # Ytrain,Ytest=Y[train],Y[test]\n",
    "    model.fit(X_train,y_train)\n",
    "    ypredict=model.predict(X_test)\n",
    "    modelscore_RFE_allfeatures.append([name,metrics.accuracy_score(y_test,ypredict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['rfboost_allFeatures', 0.9999159239952917]]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelscore_RFE_allfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
